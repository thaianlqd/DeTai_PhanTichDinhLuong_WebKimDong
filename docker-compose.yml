#note 1: không sử dụng đến kafka và zookeeper
# services:
#   spark_container:
#     image: bitnami/spark:latest
#     container_name: spark_container
#     environment:
#       - SPARK_MODE=master
#       - SPARK_MASTER_URL=spark://spark_container:7077
#     ports:
#       - "4040:4040"
#     volumes:
#       # - C:/DeTai_PhanTichDinhLuong_WebKimDong-main_version2/web/Connection_Postgresql/pyspark_Docker.py:/usr/src/app/web/Connection_Postgresql/pyspark_Docker.py
#       - D:\DeTaiPhanTichDinhLuong_Xuly_Pyspark_WebKimDong_BanChinh\DeTai_PhanTichDinhLuong_WebKimDong-main_version2_pyspark_windows\web\Connection_Postgresql:/usr/src/app/web/Connection_Postgresql
#     command: >
#        bash -c "
#         pip install psycopg2-binary pymongo &&
#         spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.0,org.postgresql:postgresql:42.5.0 /usr/src/app/web/Connection_Postgresql/pyspark_Docker.py"
#     # command: >
#     #   /bin/bash -c "pip install psycopg2-binary pymongo py4j  && \
#     #   spark-submit --master local[*] --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.0,org.postgresql:postgresql:42.5.0 /usr/src/app/web/Connection_Postgresql/pyspark_Docker.py"
#     depends_on:
#       - mongodb_container
#       - postgres_container
#     networks:
#       - my_network

#   mongodb_container:
#     image: mongo:latest
#     container_name: mymongodb_container
#     ports:
#       - "27017:27017"
#     networks:
#       - my_network

#   postgres_container:
#     image: postgres:latest
#     container_name: postgres_container
#     environment:
#       - POSTGRES_USER=postgres
#       - POSTGRES_PASSWORD=12345
#       - POSTGRES_DB=postgres
#     ports:
#       - "5432:5432"
#     networks:
#       - my_network

# networks:
#   my_network:

#note 2: sử dụng kafka và zookeeper
services:
  #note: container 1 - crawl dữ liệu 
  app_crawldata_kimdong:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app_crawldata_kimdong
    depends_on:
      - mongodb_container
    networks:
      - my_network
    restart: "no"

  #note: container 2 - spark
  spark_container:
    image: bitnami/spark:latest
    container_name: spark_container
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark_container:7077
    ports:
      - "4040:4040" # Spark Web UI
    volumes:
      - ./web/Connection_Postgresql:/usr/src/app/web/Connection_Postgresql # Đảm bảo đường dẫn đúng
    command: >
      bash -c "
        pip install --no-cache-dir psycopg2-binary kafka-python six==1.16.0 &&
        spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1,org.postgresql:postgresql:42.5.0 /usr/src/app/web/Connection_Postgresql/main_KafkaConnectPostgres.py"
    depends_on:
      - kafka_container
      - postgres_container
    networks:
      - my_network

  #note: container 3 - MongoDB
  mongodb_container:
    image: mongo:latest
    container_name: mymongodb_container
    ports:
      - "27017:27017"
    networks:
      - my_network

  #note: container 4 - postgreSQL
  postgres_container:
    image: postgres:latest
    container_name: postgres_container
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=12345
      - POSTGRES_DB=postgres
    ports:
      - "5432:5432"
    networks:
      - my_network

  #note: container 5 - pgadmin4 
  pgadmin_container:
    image: dpage/pgadmin4:latest
    container_name: pgadmin_container
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@localhost.com
      - PGADMIN_DEFAULT_PASSWORD=12345
    ports:
      - "5050:80"
    depends_on:
      - postgres_container # Đảm bảo PostgreSQL khởi động trước
    networks:
      - my_network

  #note: container 6 - zookeeper
  zookeeper_container:
    image: confluentinc/cp-zookeeper:7.3.2
    container_name: zookeeper_container
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181 # Cổng mà client sẽ kết nối đến Zookeeper
      - ZOOKEEPER_TICK_TIME=2000 # Thời gian tick của Zookeeper (đơn vị: ms)
    ports:
      - "2181:2181" # Cổng mà Zookeeper lắng nghe
    networks:
      - my_network # Kết nối vào mạng my_network

  #note: container 7-  Kafka 
  kafka_container:
    image: confluentinc/cp-kafka:7.3.2
    container_name: kafka_container
    ports:
      - "9092:9092" # Cổng Kafka cho các client ngoài container kết nối
    environment:
      - KAFKA_BROKER_ID=1 # ID của Kafka Broker (nếu có nhiều broker, mỗi broker cần một ID duy nhất)
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper_container:2181 # Kafka kết nối đến Zookeeper ở cổng 2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka_container:29092,PLAINTEXT_HOST://localhost:9092 # Các địa chỉ Kafka để client kết nối
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT # Định nghĩa các giao thức bảo mật
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT # Tên listener cho việc giao tiếp giữa các brokers
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 # Số bản sao của topic offset, ở đây là 1 (chỉ có một broker)
    depends_on:
      - zookeeper_container # Kafka phải đợi Zookeeper khởi động trước
    networks:
      - my_network

  #note: container 8 - kafdrop 
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    depends_on:
      - kafka_container
    environment:
      KAFKA_BROKERCONNECT: "kafka_container:29092"
    ports:
      - "9000:9000" # Kafdrop Web UI
    networks:
      - my_network

  #note: container 9 - airflow_init
  airflow_init:
    image: apache/airflow:2.10.3
    env_file:
      - .env # Đảm bảo chỉ định file .env
    depends_on:
      - postgres_local_container
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: "airflow db init"
    networks:
      - my_network

  #note: container 10 - airflow_webserver
  airflow_webserver:
    image: apache/airflow:2.10.3
    container_name: airflow_webserver
    env_file:
      - .env # Đảm bảo chỉ định file .env
    ports:
      - "8080:8080"
    depends_on:
      - postgres_local_container
      - airflow_init
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      bash -c " pip install --upgrade pip && \ pip install confluent-kafka pymongo six==1.16.0 python-dateutil && \ airflow db init &&  \ (airflow users create --username thaianlqd050204 --password 12345 --firstname Thai --lastname An --role Admin --email thaianlqd050204@example.com ||  echo 'User already exists') && \ airflow webserver "

    networks:
      - my_network

  #note: container 11 - airflow_scheduler
  airflow_scheduler:
    image: apache/airflow:2.10.3
    container_name: airflow_scheduler
    env_file:
      - .env # Đảm bảo chỉ định file .env
    depends_on:
      - postgres_local_container
      - airflow_init
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    # command: "airflow scheduler"
    command: >
      bash -c " pip install --upgrade pip && \ pip install confluent-kafka pymongo six==1.16.0 python-dateutil && \ airflow db init && \ airflow scheduler "

    networks:
      - my_network

  #note: container 12 - postgres_local_container 
  postgres_local_container:
    image: postgres:latest
    container_name: postgres_local_container
    environment:
      - POSTGRES_USER=myuser
      - POSTGRES_PASSWORD=12345
      - POSTGRES_DB=airflow
    ports:
      - "5433:5432" # Kết nối từ localhost:5433 đến PostgreSQL container (bên trong container vẫn là 5432)
    networks:
      - my_network

networks:
  my_network:
    driver: bridge
